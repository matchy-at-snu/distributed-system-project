# Useful links
// wisper: will look ugly

## Step 1

## Step 2

## Step 3

## Step 4
https://cloud.google.com/sdk/gcloud/reference/dataproc
https://spark.apache.org/docs/latest/configuration.html#available-properties
https://stackoverflow.com/questions/24622108/apache-spark-the-number-of-cores-vs-the-number-of-executors
Above two links for adjusting number of nodes and working threads on each node for spark job. In a nutshell, **--num-excutors {nodeNum} --executor-cores {threadsPerNode} --executor-memory {memPerNode}**

## Step 5
